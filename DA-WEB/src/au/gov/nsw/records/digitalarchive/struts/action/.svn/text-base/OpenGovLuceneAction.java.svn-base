package au.gov.nsw.records.digitalarchive.struts.action;

import java.io.File;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.UnsupportedEncodingException;
import java.net.URLEncoder;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Properties;

import javax.servlet.http.HttpServletRequest;
import javax.servlet.http.HttpServletResponse;

import org.apache.log4j.Logger;
import org.apache.lucene.analysis.Analyzer;
import org.apache.lucene.analysis.standard.StandardAnalyzer;
import org.apache.lucene.document.Document;
import org.apache.lucene.document.Field;
import org.apache.lucene.facet.index.CategoryDocumentBuilder;
import org.apache.lucene.facet.search.FacetsCollector;
import org.apache.lucene.facet.search.params.FacetSearchParams;
import org.apache.lucene.facet.search.results.FacetResult;
import org.apache.lucene.facet.search.results.FacetResultNode;
import org.apache.lucene.facet.taxonomy.TaxonomyReader;
import org.apache.lucene.facet.taxonomy.TaxonomyWriter;
import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyReader;
import org.apache.lucene.facet.taxonomy.directory.DirectoryTaxonomyWriter;
import org.apache.lucene.index.CorruptIndexException;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.IndexWriter;
import org.apache.lucene.index.IndexWriterConfig;
import org.apache.lucene.index.IndexWriterConfig.OpenMode;
import org.apache.lucene.queryParser.MultiFieldQueryParser;
import org.apache.lucene.queryParser.ParseException;
import org.apache.lucene.queryParser.QueryParser;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.MultiCollector;
import org.apache.lucene.search.Query;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.TopScoreDocCollector;
import org.apache.lucene.search.highlight.Formatter;
import org.apache.lucene.search.highlight.Fragmenter;
import org.apache.lucene.search.highlight.Highlighter;
import org.apache.lucene.search.highlight.InvalidTokenOffsetsException;
import org.apache.lucene.search.highlight.QueryScorer;
import org.apache.lucene.search.highlight.Scorer;
import org.apache.lucene.search.highlight.SimpleFragmenter;
import org.apache.lucene.search.highlight.SimpleHTMLFormatter;
import org.apache.lucene.store.Directory;
import org.apache.lucene.store.FSDirectory;
import org.apache.lucene.util.Version;
import org.apache.struts.action.Action;
import org.apache.struts.action.ActionForm;
import org.apache.struts.action.ActionForward;
import org.apache.struts.action.ActionMapping;
import org.springframework.core.io.ClassPathResource;

import au.gov.nsw.records.digitalarchive.ORM.UploadedFile;
import au.gov.nsw.records.digitalarchive.base.Constants;
import au.gov.nsw.records.digitalarchive.search.FacetResultItem;
import au.gov.nsw.records.digitalarchive.search.LuceneSearchParams;
import au.gov.nsw.records.digitalarchive.search.OpenGovSearchResult;
import au.gov.nsw.records.digitalarchive.search.SearchResult;
import au.gov.nsw.records.digitalarchive.search.SearchResultItem;
import au.gov.nsw.records.digitalarchive.service.FileService;
import au.gov.nsw.records.digitalarchive.service.FileServiceImpl;
import au.gov.nsw.records.digitalarchive.struts.form.SearchForm;

public class OpenGovLuceneAction extends Action {
	
	public ActionForward execute(ActionMapping mapping, 
		     					 ActionForm form,
		     					 HttpServletRequest request, 
		     					 HttpServletResponse response) 
	{	
	
		SearchForm searchForm = (SearchForm)form;
		ActionForward forward = null;
		String searchQuery = "";
		
		if (searchForm.getQuery() == null)
		{
			searchQuery = "";
		}else
		{
			searchQuery = searchForm.getQuery();
		}
		
		try {
			forward = new ActionForward("/search_result/search_result.jsp?q=" + URLEncoder.encode(searchQuery,"ISO-8859-1"));
		} catch (UnsupportedEncodingException e) {
			forward = new ActionForward("/search_result/search_result.jsp?q=" + searchQuery);			
			e.printStackTrace();
		}		
		return forward;
	}
	
	private static IndexWriter writer;
	private static TaxonomyWriter taxo;
	private static ClassPathResource cpr = new ClassPathResource("lucene.properties");
	
	private static final String INDEX_LOC_PROPERTY = "indexlocation";
	private static final String TEXO_LOC_PROPERTY = "taxolocation";
	
	Directory indexDirectory;
	Directory taxonomyDirectory;
	private static final File INDEX_PATH = new File(Constants.LUCENE_INDEX);
	private static final File TAXONOMY_PATH = new File(Constants.TAXONOMY);
	
	private int numTotalHits;
	private static Logger log = Logger.getLogger(OpenGovLuceneAction.class);
	
	public OpenGovLuceneAction() throws IOException {
	    this.indexDirectory = FSDirectory.open(INDEX_PATH);
	    this.taxonomyDirectory = FSDirectory.open(TAXONOMY_PATH);
	  }
	
	public CategoryDocumentBuilder startWriting() throws IOException{
		Properties prop = new Properties();
		prop.load(new FileInputStream(cpr.getFile()));
		
		Directory dir = FSDirectory.open(new File(prop.getProperty(INDEX_LOC_PROPERTY)));
		Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_31);
		IndexWriterConfig iwc = new IndexWriterConfig(Version.LUCENE_31, analyzer);
		// Create a new index in the directory, removing any
		// previously indexed documents:
		iwc.setOpenMode(OpenMode.CREATE);

		// Optional: for better indexing performance, if you
		// are indexing many documents, increase the RAM
		// buffer.  But if you do this, increase the max heap
		// size to the JVM (eg add -Xmx512m or -Xmx1g):
		iwc.setRAMBufferSizeMB(256.0);

		writer = new IndexWriter(dir, iwc);
		
		Directory taxoDir = FSDirectory.open(new File(prop.getProperty(TEXO_LOC_PROPERTY)));
		taxo = new DirectoryTaxonomyWriter(taxoDir, OpenMode.CREATE);
		
		return new CategoryDocumentBuilder(taxo);
	}
	
	public void commit() throws CorruptIndexException, IOException{
		taxo.commit();
		writer.commit();
	}
	
	public void finishWriting() throws CorruptIndexException, IOException{
		taxo.close();
		writer.close();
	}
	
	public void indexDocuments(List<Document> docs, Class<?> clazz){
		try {
			for (Document doc:docs){
				doc.add(new Field("class", clazz.getName(), Field.Store.NO, Field.Index.ANALYZED));
				writer.addDocument(doc);
			}
		} catch (IOException e) {
			e.printStackTrace();
		}
	}
	
	public OpenGovSearchResult searchText(String searchText, FacetSearchParams facets, Integer pageNumber, Integer pageSize) 
	{
		Map<String, String> resultEntity = new HashMap<String, String>();
		List<FacetResultItem> facetResults = new ArrayList<FacetResultItem>();

		File INDEX_PATH = new File(Constants.LUCENE_INDEX);
	    Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_36);
		
		try 
		{
			IndexReader reader = IndexReader.open(FSDirectory.open(INDEX_PATH)); 
			IndexSearcher searcher = new IndexSearcher(reader);
			
			String[] fields = {"title", "keyword", "agencyname", "filename", "content", "type", "coverage"};
			
			QueryParser query = new MultiFieldQueryParser(Version.LUCENE_36, fields, analyzer);
			            
			TopScoreDocCollector collector = TopScoreDocCollector.create(pageNumber.intValue() * pageSize.intValue(), false);
			TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxonomyDirectory);

			FacetsCollector facetsCollector = new FacetsCollector(facets, reader, taxoReader);
			
			Query searchQuery = query.parse(searchText);
            
			System.out.println("Searching " + searcher.maxDoc() + " documents.");
            
			searcher.search(searchQuery, MultiCollector.wrap(collector, facetsCollector));
            
			TopDocs docs = collector.topDocs((pageNumber.intValue()-1)*pageSize.intValue(), pageSize.intValue());
			this.numTotalHits = collector.getTotalHits();
			
	        Formatter formatter = new SimpleHTMLFormatter("<span class=\"highlighter\">","</span>");
	        Scorer fragmentScorer = new QueryScorer(searchQuery);
	        Highlighter highlighter = new Highlighter(formatter, fragmentScorer);
	        Fragmenter fragmenter = new SimpleFragmenter(150);
	        highlighter.setTextFragmenter(fragmenter);
	        
	        System.out.println("Found " + numTotalHits);
	       
	        for (ScoreDoc hit:docs.scoreDocs)
	        {
		    	Document doc = searcher.doc(hit.doc);
	              
	            String filename = doc.get("filename");
	            String agencyname = doc.get("agencyname");
	            String keyword = doc.get("keyword");
	            String title = doc.get("title");
	            //String description = doc.get("description");
	            String content = doc.get("content");
	            String fileID = doc.get("fileID");
		              
	            String hl_filename = highlighter.getBestFragment(analyzer, "filename", filename);
	            String hl_agencyname = highlighter.getBestFragment(analyzer, "agencyname", agencyname);
	            String hl_keyword = highlighter.getBestFragment(analyzer, "keyword", keyword);
	            String hl_title = highlighter.getBestFragment(analyzer, "title", title);
	            //String hl_description = highlighter.getBestFragment(analyzer, "description", description);
	            String hl_content = highlighter.getBestFragment(analyzer, "content", content);
	
	            if(hl_filename == null)
	            {hl_filename = filename.substring(0, Math.min(150, filename.length()));}
	              
	            if(hl_agencyname == null)
	            {hl_agencyname = agencyname.substring(0, Math.min(150, agencyname.length()));}
	
	            if(hl_keyword == null)
	            {hl_keyword = keyword.substring(0, Math.min(150, keyword.length()));}
	
	            if(hl_title == null)
	            {hl_title = title.substring(0, Math.min(150, title.length()));}
	              
	            //if(hl_description == null)
	            //{hl_description = description.substring(0, Math.min(150, description.length()));}
	              
	            if(hl_content == null)
	            {hl_content = content.substring(0, Math.min(150, content.length()));}
	                  
	            FileService fs = new FileServiceImpl();
	            UploadedFile uFile = fs.loadFile(Integer.parseInt(fileID));
	            String fileName = uFile.getFileName();
	            String fileSize = uFile.getSize();
	            final StringBuilder builder = new StringBuilder();
	              
	            builder.append("...... " + hl_content + "......").append("<br/><br/><strong><span class=\"lightblue\"><a href=\"download/" + fileID + "\" title=\"" + fileName + "\">" + hl_filename + "</a>&nbsp;&nbsp;|&nbsp;&nbsp;Size:&nbsp;" + fileSize +"</span></strong>");      
	            resultEntity.put(fileID, builder.toString());
	        }

            System.out.println("\n\n\n\n\n\n ..............");

	        for (FacetResult facetResult : facetsCollector.getFacetResults()) {
	            FacetResultNode resultNode = facetResult.getFacetResultNode();

	            if (resultNode.getNumSubResults() > 0) {
	              int numSubResults = resultNode.getNumSubResults();
	              String facetName = resultNode.getLabel().lastComponent();

	              for (FacetResultNode node : resultNode.getSubResults()) {
	                //String label = node.getLabel().lastComponent();
	            	  String label = node.getLabel().toString();
	            	  Integer count = (int) node.getValue();
	                System.out.println(label + ": " + "[" + count + "]");
	              }
	            }
	          }
	       
	        
	        for (FacetResult fr:facetsCollector.getFacetResults()){
				List<FacetResultItem> subItems = new ArrayList<FacetResultItem>();
				facetResults.add(new FacetResultItem(fr.getFacetResultNode().getLabel().lastComponent().toString(), fr.getFacetResultNode().getLabel().lastComponent().toString(), 0, subItems));
				for (FacetResultNode rn: fr.getFacetResultNode().getSubResults()){
					subItems.add(new FacetResultItem(rn.getLabel().lastComponent().toString().replace(fr.getFacetResultNode().getLabel().lastComponent().toString() + "/", ""), fr.getFacetResultNode().getLabel().lastComponent().toString(), new Double(rn.getValue()).intValue(), null));
				}
			}
            searcher.close();
            reader.close();
		} catch (Exception e) {
			e.printStackTrace();
			System.out.println("Exception");
		}
		return new OpenGovSearchResult(resultEntity, facetResults, this.numTotalHits);

	}
	
	
	private SearchResult search(Query query, FacetSearchParams facets, Integer page, Integer size){
		List<SearchResultItem> searchResults = new ArrayList<SearchResultItem>(); 
		List<FacetResultItem> facetResults = new ArrayList<FacetResultItem>();
		int numTotalHits = 0;
		try {
			Properties prop = new Properties();
			prop.load(new FileInputStream(cpr.getFile()));
			
			IndexReader indexReader = IndexReader.open(FSDirectory.open(new File(prop.getProperty(INDEX_LOC_PROPERTY))));
			IndexSearcher searcher = new IndexSearcher(indexReader);
			Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_31);

			Directory taxoDir = FSDirectory.open(new File(prop.getProperty(TEXO_LOC_PROPERTY)));
			TaxonomyReader taxoReader = new DirectoryTaxonomyReader(taxoDir);
			FacetsCollector facetsCollector = new FacetsCollector(facets, indexReader, taxoReader);
			
			TopScoreDocCollector docCollector = TopScoreDocCollector.create(page.intValue()*size.intValue(), true);
			
			searcher.search(query, MultiCollector.wrap(docCollector, facetsCollector));
			
			TopDocs docs = docCollector.topDocs((page.intValue()-1)*size.intValue(), size.intValue());
			numTotalHits = docCollector.getTotalHits();
			log.info(numTotalHits + " total matching documents");
			
			for (ScoreDoc hit:docs.scoreDocs){
				Document doc = searcher.doc(hit.doc);
				Formatter formatter = new SimpleHTMLFormatter("<b>","</b>");
				Scorer fragmentScorer = new QueryScorer(query);
				Highlighter highlighter = new Highlighter(formatter, fragmentScorer);
				Fragmenter fragmenter = new SimpleFragmenter(150);
				highlighter.setTextFragmenter(fragmenter);
				searchResults.add(new SearchResultItem(doc.get("type"), doc.get("title"), highlighter.getBestFragment(analyzer, "content", doc.get("content")), doc.get("id"), doc.get("url")));
			}
			for (FacetResult fr:facetsCollector.getFacetResults()){
				List<FacetResultItem> subItems = new ArrayList<FacetResultItem>();
				facetResults.add(new FacetResultItem(fr.getFacetResultNode().getLabel().toString(), fr.getFacetResultNode().getLabel().toString(),0, subItems));
				for (FacetResultNode rn: fr.getFacetResultNode().getSubResults()){
					subItems.add(new FacetResultItem(rn.getLabel().toString().replace(fr.getFacetResultNode().getLabel().toString() + "/", ""), fr.getFacetResultNode().getLabel().toString(), new Double(rn.getValue()).intValue(), null));
				}
			}
			searcher.close();
			indexReader.close();
		} catch (CorruptIndexException e) {
			e.printStackTrace();
		} catch (InvalidTokenOffsetsException e){
			e.printStackTrace();
		} catch (IOException e) {
			e.printStackTrace();
		}
		return new SearchResult(searchResults, facetResults, numTotalHits);
	}

	public SearchResult search(LuceneSearchParams params){
		String classQuery = "";
		int i = 0;
		// multi-entity search
		for (Class<?> clazz: params.getClazz()){
			if (i++>0){
				classQuery += " OR ";
			}
			classQuery += String.format("class:( +\"%s\")", clazz.getName());
		}
		String facetCondition = "";
		if (params.getLocation()!=null){
			facetCondition += String.format(" AND location:( +\"%s\")", params.getLocation());
		}
		if (params.getSeries()!=null){
			facetCondition += String.format(" AND series:( +\"%s\")", params.getSeries());
		}
		
		try {
			String queryText = params.getQuery() + String.format(" AND (%s)", classQuery) + facetCondition; 
			log.info("Query:" + queryText);
			//general query
			Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_31);
			MultiFieldQueryParser queryParser = new MultiFieldQueryParser(Version.LUCENE_31, new String[] {"title", "content"}, analyzer);
			Query baseQuery = queryParser.parse(queryText);
			
			//baseQuery = DrillDown.query(baseQuery, new CategoryPath("location", "Western Sydney Records Centre, Kingswood"));
			
			return search(baseQuery, params.getFacetParams(), params.getPage(), params.getSize());
		} catch (ParseException e) {
			e.printStackTrace();
		} catch (Exception e){
			e.printStackTrace();
		}
		
    return new SearchResult(new ArrayList<SearchResultItem>(), new ArrayList<FacetResultItem>(), 0); 
	}

	public int getNumTotalHits() {
		return this.numTotalHits;
	}

	public void setNumTotalHits(int numTotalHits) {
		this.numTotalHits = numTotalHits;
	}
	
}
